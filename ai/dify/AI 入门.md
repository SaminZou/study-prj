```yaml
title: AI 入门
author: samin
date: 2025-08-04
```

- 意图识别

- 记忆组成部分：推导出来的事实、偏好、回忆

- 人类经验 -> 特定工作流 -> 原子化组件 -> 通用工作流

# Agent

核心能力（大脑）：基于大模型（LLM），就像人类大脑的中枢，负责理解问题、生成思路

三件套关键要素：

1、记忆（存储信息）：短期记忆：记住当前对话的上下文，比如你刚说过 “喜欢海边”，它会在接下来的回复里记得这个偏好，但容量有限，就像人脑临时记东西，时间长了会忘。

2、长期记忆：连接外部数据库或文件，比如你上传一本 PDF 手册，它能长期存储并随时调用里面的内容，相当于有个无限容量的笔记本，专门存复杂任务需要的资料。

3、工具（调用外部能力）：遇到自己解决不了的问题，比如查天气、算数据，它会自动调用对应的工具（比如天气 API、计算器），就像人干活时随手拿扳手、螺丝刀，借外力把事办好。

## 模式

- ReAct
- CodeAct
- Self-Reflection
- Planner-style

## 任务调度

多任务同时处理的时候，涉及任务拆分、冲突协调、上下文隔离、失败回滚

## 记忆（Memory Controller）

- Scratchpad
- Semantic Memory（Embedding + Search）
- Agentic Memory（具备写入、更新、清理能力的长期记忆系统）

## 工具调用

- 工具注入：工具是动态注册和发现的，不是静态写死的
- 参数对齐：不靠 Prompt 拼接，而是通过 Structured Output（结构化输出），让 LLM 生成与工具接口 Schema 完全对齐的 JSON，实现自动调用
- 工具路由（Tool Router）：在众多工具中，需要一个独立的“工具选择器”或者一个更小的模型，来决定当前步骤最应该调用哪个工具，而不是让主 LLM 去猜
- 容错与回退（Fallback）：工具调用失败，不能直接放弃。系统必须有重试、使用备用工具、或者向用户澄清问题的 Fallback 策略。

## 调优

- 性能问题，增加 Tracing 跟踪是 Token 太大、检索太慢、工具链太长等问题
- 安全问题：Prompt注入、数据越权、Token滥用

# AI 模型组成

- 神经网络架构：如 Transformer 架构
- 大规模参数量
- 训练数据集
- 优化算法
- 技术架构：包括数据处理、模型训练、推理、以及应用部署等环节

# DeepSeek

Deepseek 三个突出特点：性能、开源、成本

## 1 性能

Deepseek R1 实际性能对表 GPT-o1,有些能力甚至超过 o1

## 2 开源

整个模型不仅开源，开发团队还把研发过程写成论文公开发布（ MIT 协议 ）

> 行业现状：性能好的模型很贵，开源的性能不大行。Deepseek 是第一个开源且性能对标 o1 的大模型

## 3 成本

DeepSeek 一共 6 万张计算卡，大概是 255 万，训练成本远低于其他大模型

DeepSeek R1 满血版拥有 6710 亿个参数，部署至少需要 1T 内存和双 H100 80G

以 token 为单位，1 个英文字符约 0.3 个 token，1 个中文字符约 0.6 个 token，即 1 token 可对应 1-2 个中文汉字，或对应 3-4 个英文字符，或 0.75 个英文单词

# AI 应用工程师

AI 应用工程师主要处于应用层，负责将 AI 大模型的技术转化为实际的产品和服务。

具体来说，AI 应用工程师的工作可以分为以下几个阶段：
- API 应用开发：工程师通过调用 AI 大模型的 API 接口，开发具体的应用程序。例如，使用 OpenAI 的 API 进行文本生成或图像识别。
- 应用架构实践：工程师需要理解并实践AI大模型的应用架构，包括 Agent 模型框架、RAG（检索增强生成）技术等。
- 应用部署与优化：在实际应用中，工程师需要将模型部署到生产环境中，并根据实际需求进行优化，以提高模型的效率和性能。

AI 应用工程师处于 AI 技术落地的最后阶段，他们通过开发和部署 AI 应用，将模型的能力转化为实际的解决方案，服务于不同的行业和用户。