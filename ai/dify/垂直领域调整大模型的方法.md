```yaml
title: 垂直领域调整大模型的方法
author: samin
date: 2025-08-26
```

# 提示词工程

提问的时候插入

构建合适的 Prompt

结构：角色、情境、约束、任务

例：
```text
## 角色
你是一个资深 Java 程序员

## 情境
面试中需要考察算法题

## 约束
算法速度优先；Java 语法

## 任务
编写一个整数排序算法
```

# 检索增强生成

RAG，Retrieval-Augmented Generation

## 简易 RAG 搭建

- Load: 把所有的文档一股脑丢进去

- Split & Embed: 用 LangChain 的 RecursiveCharacterTextSplitter 一顿切，再调用 OpenAI 的 text-embedding-ada-002 模型，把一堆文本变成一堆看不懂的向量

- Store & Query: 把向量塞进 ChromaDB，用户提问时，也转成向量，然后做个余弦相似度检索，把最像的几个文本块（Chunk）和问题一起打包，丢给 LLM 模型

## 简易 RAG 方案常见两大问题

1. Chunk 切分：一句完整的话容易被切割，上半句在chunk A，下半句在chunk B。检索的时候，只找到了半句，造成问题
 
> 解决方案：语义切分、按标题切分

2. Embedding 模型：类似 text-embedding-ada-002 模型，对很多专业名词的理解能力为 0，会导致答非所问

> 解决方案：
> 混合检索（Hybrid Search），如向量召回一路，BM25 召回一路，两路结果再用 RRF（倒数排名融合）
> 重排序（Rerank），Reranker 模型，把召回的 Top 20 个文档打分，重新排序

## RAG 方案还需要解决的问题

LLM 生成答案造成的幻觉（Hallucination）问题。

解决方案：

- Prompt 设计：提示词工程
- 上下文拼接：召回了 10 个相关的 Chunk，怎么塞给模型？模型的上下文窗口（Context Window）有限，塞多了全是噪音。只塞最相关的那个？可能信息又不全面。（行业解法：上下文的排序，把最相关的放在开头和结尾，效果最好）
- 评估与控制：
  - 评估指标：Faithfulness（忠实度）、Answer Correctness（答案正确性）
  - 评估框架：RAGAS

## 总结

Chunk 切不好，检索就是垃圾；Embedding 选不对，召回就是白费；Rerank 不做，精准度就上不去；Prompt 不精调，生成就爱自由飞翔；上下文不控制，模型就会被噪音淹没；评估体系不建立，你永远不知道你的 Agent 是在帮你，还是在给你挖坑。

# 模型微调

Fine-tuning

通过预训练模型，使用特定领域数据对模型进行进一步的训练，调整模型的权重参数

微调的主要原因：

- 让模型更懂“专业话”：通用模型就像一个“万事通”，它学过很多东西，但对一些特别专业的领域（比如医学、法律、金融）可能不会特别精通。通过微调，我们可以给模型“补课”，让它学会这些专业领域的知识，从而在这些领域表现得更好。
- 让模型适应不同的“工作”：不同的任务对模型的要求不一样。比如，有些任务需要模型判断一段文字是好是坏（比如评论是正面还是负面），这就需要模型输出一个明确的答案；而有些任务需要模型写一篇文章或者回答问题，这就需要模型生成流畅、连贯的文字。微调可以让模型根据任务的需求调整自己的能力，更好地完成这些“工作”。
- 让模型表现得更“平衡”：通用模型在很多通用任务上表现不错，但在一些特定任务上可能会“失衡”。比如，它可能会对某些问题过于敏感，或者对某些问题反应不够。通过微调，我们可以调整模型的“参数”，就像调整汽车的引擎一样，让它在特定任务上表现得更“平衡”。
- 保护数据的隐私和安全：有时候，我们的数据可能包含一些敏感信息，比如公司的机密文件或者个人隐私。这些数据不能随便上传到云端，否则可能会泄露。微调允许我们在自己的电脑或服务器上训练模型，这样数据就一直掌握在自己手里，不用担心泄露。
- 节省时间和成本：如果从头开始训练一个模型，就像从零开始盖一座房子，需要很多时间和资源。而微调就像是在现成的房子里进行装修，只需要调整一下细节，就可以让它更适合自己的需求。这样不仅节省时间和成本，而且微调后的模型在特定任务上表现更好，用起来也更高效。
